{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":4597,"status":"ok","timestamp":1729545362140,"user":{"displayName":"Franc Menz","userId":"08362726975090090448"},"user_tz":0},"id":"3GR7YUhnfqXh"},"outputs":[],"source":["import PIL as PIL\n","import torch as torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch import optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UEy1jpUMw3tc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:18\u003c00:00, 9177116.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# is time for as to prepare our data to feed it\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n","    ])\n","\n","\n","train_data = datasets.CIFAR10(root=\"./data\", train=True,download=True, transform=transform )\n","test_data = datasets.CIFAR10(root=\"./data\",train= False, download=True, transform=transform)\n","\n","train_loader = DataLoader(dataset=train_data,batch_size=32,shuffle=True)\n","test_loader = DataLoader(dataset=test_data,batch_size=32,shuffle=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":508,"status":"ok","timestamp":1729412824106,"user":{"displayName":"Franc Menz","userId":"08362726975090090448"},"user_tz":0},"id":"4p2w1r5Ew5z2"},"outputs":[],"source":["# is time for as to build our CNN model to do the classification for as\n","class CIPHAR_NET(nn.Module):\n","  def __init__(self):\n","    super(CIPHAR_NET,self).__init__()\n","    self.conv1 = nn.Conv2d(3,12,4, padding=1) #new shape (12,29,29)\n","    self.pool1 = nn.MaxPool2d(2,2) # (12,14,14)\n","\n","    self.conv2 = nn.Conv2d(12,24,4, padding=1) # (24,11,11)\n","    self.pool2 = nn.MaxPool2d(2,2)  # (24,5,5)\n","\n","    self.conv3 = nn.Conv2d(24,36,4, padding=1) # (36,3,3)\n","    self.pool3 = nn.MaxPool2d(2,2) # (36,1,1)\n","\n","    self.fc1 = nn.Linear(36 * 1 * 1, 60) # flatten its hear\n","    self.fc2 = nn.Linear(60,10)\n","\n","\n","  def forward(self, x):\n","    x = self.pool1(F.relu(self.conv1(x)))\n","    x = self.pool2(F.relu(self.conv2(x)))\n","    x = self.pool3(F.relu(self.conv3(x)))\n","    x = x.view(x.size(0), -1)\n","\n","    x = F.relu(self.fc1(x))\n","    x=self.fc2(x)\n","\n","    return x\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1729412825507,"user":{"displayName":"Franc Menz","userId":"08362726975090090448"},"user_tz":0},"id":"Cg4OgUNmqUWY"},"outputs":[],"source":["# creating an instance of our CIPHARNET\n","model = CIPHAR_NET()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1729412825507,"user":{"displayName":"Franc Menz","userId":"08362726975090090448"},"user_tz":0},"id":"Bx36lG7FdDzY"},"outputs":[],"source":["# setting up our loss function and optimizer\n","evaluation = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr= 0.01)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":18,"status":"error","timestamp":1729412825507,"user":{"displayName":"Franc Menz","userId":"08362726975090090448"},"user_tz":0},"id":"1KkydaCVtyyI"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 10 / 9  Loss: 1.39\n","Epoch: 20 / 19  Loss: 1.34\n","Epoch: 30 / 29  Loss: 1.32\n","Epoch: 40 / 39  Loss: 1.30\n","Epoch: 50 / 49  Loss: 1.29\n","Epoch: 60 / 59  Loss: 1.31\n","Epoch: 70 / 69  Loss: 1.27\n","Epoch: 80 / 79  Loss: 1.27\n","Epoch: 90 / 89  Loss: 1.27\n","Epoch: 100 / 99  Loss: 1.27\n"]}],"source":["# we are going to train our model on the train_loader dataset\n","Epoch = 100\n","losses = []\n","running_loss = 0\n","for epoch in range(Epoch):\n","  running_loss = 0\n","  # loop through the train_loader to get the input and the labels\n","  for input, labels in train_loader:\n","\n","\n","    # set the optimizer to zero grad\n","    optimizer.zero_grad()\n","    output = model(input)\n","\n","    # compute the loss\n","    loss = evaluation(output,labels)\n","\n","    # feeding the loss back in to the network\n","    loss.backward()\n","\n","    # update the optimizer\n","    optimizer.step()\n","\n","    running_loss = running_loss+loss.item()\n","    #  calculating for the average loss\n","  average_loss = running_loss / len(train_loader)\n","  losses.append(running_loss)\n","\n","\n","    # printing the loss after every 10 epoch\n","  if (epoch + 1) % 10 == 0:\n","    print(f\"Epoch: {epoch + 1} / {epoch}  Loss: {average_loss:2f%}\")\n","\n","\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMPa+ITWRXqP6ONZplduDEh","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}