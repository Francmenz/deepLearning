{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMnLy6ZInAWePQ5sAbnwz8g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"emb_pf8H_KTW","executionInfo":{"status":"error","timestamp":1729244495280,"user_tz":0,"elapsed":652,"user":{"displayName":"Franc Menz","userId":"08362726975090090448"}},"outputId":"4b433bae-50a7-4558-9d1c-d046b3b5dc49"},"outputs":[{"output_type":"error","ename":"error","evalue":"OpenCV(4.10.0) /io/opencv/modules/dnn/src/darknet/darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'readNetFromDarknet'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6caaae34468b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load YOLO model - Make sure to download these files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov3.weights\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yolov3.cfg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlayer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLayerNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutput_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetUnconnectedOutLayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/dnn/src/darknet/darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'readNetFromDarknet'\n"]}],"source":["import cv2\n","import numpy as np\n","\n","# Load YOLO model - Make sure to download these files\n","net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n","layer_names = net.getLayerNames()\n","output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n","\n","# Load class labels (if your model is trained for parking spots)\n","classes = []\n","with open(\"coco.names\", \"r\") as f:\n","    classes = [line.strip() for line in f.readlines()]\n","\n","# Function to detect parking spots in an image\n","def detect_parking_spots(image):\n","    height, width, channels = image.shape\n","    # Convert the image to a blob\n","    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n","    net.setInput(blob)\n","    outs = net.forward(output_layers)\n","\n","    class_ids = []\n","    confidences = []\n","    boxes = []\n","\n","    # Loop over each detection\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence > 0.5:  # Confidence threshold\n","                # Object detected\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","\n","                # Rectangle coordinates\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","\n","                boxes.append([x, y, w, h])\n","                confidences.append(float(confidence))\n","                class_ids.append(class_id)\n","\n","    # Non-max suppression to remove overlapping boxes\n","    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n","\n","    available_spots = 0\n","    occupied_spots = 0\n","\n","    # Iterate over detections and classify parking spots\n","    for i in range(len(boxes)):\n","        if i in indexes:\n","            x, y, w, h = boxes[i]\n","            label = str(classes[class_ids[i]])\n","            confidence = confidences[i]\n","\n","            # For simplicity, assuming label 'car' indicates an occupied spot\n","            if label == 'car':\n","                color = (0, 0, 255)  # Red for occupied\n","                occupied_spots += 1\n","            else:\n","                color = (0, 255, 0)  # Green for available\n","                available_spots += 1\n","\n","            # Draw bounding box\n","            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n","            cv2.putText(image, f\"{label} {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n","\n","    # Display counts\n","    cv2.putText(image, f\"Available Spots: {available_spots}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n","    cv2.putText(image, f\"Occupied Spots: {occupied_spots}\", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n","\n","    return image, available_spots, occupied_spots\n","\n","# Process an image or video\n","def process_image_or_video(input_source):\n","    cap = cv2.VideoCapture(input_source)\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # Detect parking spots in the current frame\n","        result_frame, available_spots, occupied_spots = detect_parking_spots(frame)\n","\n","        # Show the result\n","        cv2.imshow(\"Parking Spot Detection\", result_frame)\n","\n","        # Break the loop on 'q' key press\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","# Main function to run the model\n","if __name__ == \"__main__\":\n","    # You can change 'video.mp4' to 0 to use the webcam or provide an image path\n","    process_image_or_video('parking_lot_video.mp4')  # Video or 'parking_image.jpg' for an image\n"]}]}